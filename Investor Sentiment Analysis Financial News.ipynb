{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e1e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5bbb40",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe8b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all-data.csv\", header=None, encoding='ISO-8859-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5286c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {0: \"Sentiment\", 1: \"News\"}\n",
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080cb9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               News\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63173eee",
   "metadata": {},
   "source": [
    "# Get embeddings for news with SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff3e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d88ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"News\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf27f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe4f14f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1])\n",
    "print(embeddings[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49fc5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame(embeddings, columns=[f'embedding_{i+1}' for i in range(embeddings.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa34c904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_375</th>\n",
       "      <th>embedding_376</th>\n",
       "      <th>embedding_377</th>\n",
       "      <th>embedding_378</th>\n",
       "      <th>embedding_379</th>\n",
       "      <th>embedding_380</th>\n",
       "      <th>embedding_381</th>\n",
       "      <th>embedding_382</th>\n",
       "      <th>embedding_383</th>\n",
       "      <th>embedding_384</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033103</td>\n",
       "      <td>-0.100423</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>-0.066260</td>\n",
       "      <td>0.018836</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>-0.035340</td>\n",
       "      <td>-0.077344</td>\n",
       "      <td>-0.009411</td>\n",
       "      <td>-0.007487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022584</td>\n",
       "      <td>0.069428</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>-0.089813</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.018754</td>\n",
       "      <td>-0.127873</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>-0.022025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084485</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>-0.002329</td>\n",
       "      <td>-0.056259</td>\n",
       "      <td>-0.113815</td>\n",
       "      <td>-0.121623</td>\n",
       "      <td>-0.061220</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>-0.064939</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060081</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>-0.040411</td>\n",
       "      <td>-0.021518</td>\n",
       "      <td>-0.055036</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>-0.034406</td>\n",
       "      <td>0.047268</td>\n",
       "      <td>0.056127</td>\n",
       "      <td>-0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043609</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.040851</td>\n",
       "      <td>-0.046114</td>\n",
       "      <td>0.062376</td>\n",
       "      <td>-0.028048</td>\n",
       "      <td>-0.046857</td>\n",
       "      <td>-0.038051</td>\n",
       "      <td>-0.068427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>-0.097364</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>-0.012047</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.038261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.029139</td>\n",
       "      <td>-0.037931</td>\n",
       "      <td>-0.010632</td>\n",
       "      <td>0.047564</td>\n",
       "      <td>-0.011515</td>\n",
       "      <td>-0.073900</td>\n",
       "      <td>0.040631</td>\n",
       "      <td>-0.057157</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.043284</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.048531</td>\n",
       "      <td>-0.034414</td>\n",
       "      <td>-0.071167</td>\n",
       "      <td>0.079625</td>\n",
       "      <td>-0.017603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.021902</td>\n",
       "      <td>-0.022826</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>-0.058745</td>\n",
       "      <td>-0.037734</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.022633</td>\n",
       "      <td>0.066558</td>\n",
       "      <td>-0.011591</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011690</td>\n",
       "      <td>-0.047741</td>\n",
       "      <td>-0.072852</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.062899</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>-0.126716</td>\n",
       "      <td>-0.077100</td>\n",
       "      <td>0.065531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>0.037514</td>\n",
       "      <td>-0.031628</td>\n",
       "      <td>0.114416</td>\n",
       "      <td>0.060084</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>0.017323</td>\n",
       "      <td>-0.006961</td>\n",
       "      <td>-0.023695</td>\n",
       "      <td>-0.019650</td>\n",
       "      <td>-0.032931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047153</td>\n",
       "      <td>-0.036253</td>\n",
       "      <td>-0.089335</td>\n",
       "      <td>0.063155</td>\n",
       "      <td>-0.114799</td>\n",
       "      <td>-0.068349</td>\n",
       "      <td>-0.031357</td>\n",
       "      <td>-0.059850</td>\n",
       "      <td>-0.199711</td>\n",
       "      <td>0.050612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>-0.010111</td>\n",
       "      <td>0.053529</td>\n",
       "      <td>-0.115659</td>\n",
       "      <td>-0.004243</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>-0.027198</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>0.099848</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019655</td>\n",
       "      <td>-0.046397</td>\n",
       "      <td>-0.043783</td>\n",
       "      <td>-0.015527</td>\n",
       "      <td>-0.046047</td>\n",
       "      <td>-0.086482</td>\n",
       "      <td>-0.066512</td>\n",
       "      <td>-0.062369</td>\n",
       "      <td>-0.044434</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0.044477</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>-0.002873</td>\n",
       "      <td>-0.025707</td>\n",
       "      <td>-0.078903</td>\n",
       "      <td>0.112590</td>\n",
       "      <td>-0.039120</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064868</td>\n",
       "      <td>-0.009705</td>\n",
       "      <td>-0.028710</td>\n",
       "      <td>0.066628</td>\n",
       "      <td>-0.104506</td>\n",
       "      <td>-0.023398</td>\n",
       "      <td>-0.102364</td>\n",
       "      <td>-0.062642</td>\n",
       "      <td>-0.026184</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>-0.040445</td>\n",
       "      <td>-0.003198</td>\n",
       "      <td>0.065040</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>-0.078426</td>\n",
       "      <td>0.112104</td>\n",
       "      <td>0.038359</td>\n",
       "      <td>-0.006200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>-0.046804</td>\n",
       "      <td>-0.040203</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>-0.084330</td>\n",
       "      <td>0.068363</td>\n",
       "      <td>-0.033828</td>\n",
       "      <td>-0.067488</td>\n",
       "      <td>-0.045671</td>\n",
       "      <td>-0.021801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>0.034151</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>-0.015382</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>-0.067917</td>\n",
       "      <td>0.076618</td>\n",
       "      <td>0.032881</td>\n",
       "      <td>-0.004349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075085</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.060343</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>-0.060569</td>\n",
       "      <td>-0.061905</td>\n",
       "      <td>-0.046788</td>\n",
       "      <td>0.039337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0        0.033103    -0.100423    -0.005485    -0.066260     0.018836   \n",
       "1        0.084485     0.030830    -0.002329    -0.056259    -0.113815   \n",
       "2        0.043609     0.004894     0.004905     0.040851    -0.046114   \n",
       "3       -0.067166    -0.029139    -0.037931    -0.010632     0.047564   \n",
       "4       -0.021902    -0.022826     0.011935    -0.058745    -0.037734   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "4841     0.037514    -0.031628     0.114416     0.060084     0.015975   \n",
       "4842    -0.010111     0.053529    -0.115659    -0.004243    -0.012975   \n",
       "4843     0.044477     0.030813     0.068884     0.047986    -0.002873   \n",
       "4844    -0.040445    -0.003198     0.065040     0.009511     0.013660   \n",
       "4845     0.034151     0.033816     0.015101    -0.015382     0.041003   \n",
       "\n",
       "      embedding_6  embedding_7  embedding_8  embedding_9  embedding_10  ...  \\\n",
       "0       -0.031824    -0.035340    -0.077344    -0.009411     -0.007487  ...   \n",
       "1       -0.121623    -0.061220     0.055847    -0.064939      0.021643  ...   \n",
       "2        0.062376    -0.028048    -0.046857    -0.038051     -0.068427  ...   \n",
       "3       -0.011515    -0.073900     0.040631    -0.057157      0.001864  ...   \n",
       "4        0.007767    -0.022633     0.066558    -0.011591      0.004221  ...   \n",
       "...           ...          ...          ...          ...           ...  ...   \n",
       "4841     0.017323    -0.006961    -0.023695    -0.019650     -0.032931  ...   \n",
       "4842    -0.027198     0.014351     0.099848     0.016810     -0.004626  ...   \n",
       "4843    -0.025707    -0.078903     0.112590    -0.039120      0.016103  ...   \n",
       "4844     0.024086    -0.078426     0.112104     0.038359     -0.006200  ...   \n",
       "4845     0.032181    -0.067917     0.076618     0.032881     -0.004349  ...   \n",
       "\n",
       "      embedding_375  embedding_376  embedding_377  embedding_378  \\\n",
       "0         -0.022584       0.069428       0.011990      -0.089813   \n",
       "1          0.060081       0.006366      -0.040411      -0.021518   \n",
       "2          0.015348      -0.097364       0.010314       0.016644   \n",
       "3          0.068182       0.043284      -0.001184       0.050133   \n",
       "4          0.011690      -0.047741      -0.072852      -0.009161   \n",
       "...             ...            ...            ...            ...   \n",
       "4841      -0.047153      -0.036253      -0.089335       0.063155   \n",
       "4842       0.019655      -0.046397      -0.043783      -0.015527   \n",
       "4843       0.064868      -0.009705      -0.028710       0.066628   \n",
       "4844       0.021573      -0.046804      -0.040203       0.002362   \n",
       "4845      -0.075085      -0.003974       0.024613       0.000273   \n",
       "\n",
       "      embedding_379  embedding_380  embedding_381  embedding_382  \\\n",
       "0          0.018476      -0.019637      -0.018754      -0.127873   \n",
       "1         -0.055036       0.037341      -0.034406       0.047268   \n",
       "2          0.062900      -0.012047      -0.049860      -0.020716   \n",
       "3         -0.001276       0.048531      -0.034414      -0.071167   \n",
       "4          0.004916       0.062899       0.002259      -0.126716   \n",
       "...             ...            ...            ...            ...   \n",
       "4841      -0.114799      -0.068349      -0.031357      -0.059850   \n",
       "4842      -0.046047      -0.086482      -0.066512      -0.062369   \n",
       "4843      -0.104506      -0.023398      -0.102364      -0.062642   \n",
       "4844      -0.084330       0.068363      -0.033828      -0.067488   \n",
       "4845      -0.060343       0.029984      -0.060569      -0.061905   \n",
       "\n",
       "      embedding_383  embedding_384  \n",
       "0          0.009407      -0.022025  \n",
       "1          0.056127      -0.001998  \n",
       "2          0.020335       0.038261  \n",
       "3          0.079625      -0.017603  \n",
       "4         -0.077100       0.065531  \n",
       "...             ...            ...  \n",
       "4841      -0.199711       0.050612  \n",
       "4842      -0.044434       0.001449  \n",
       "4843      -0.026184       0.003788  \n",
       "4844      -0.045671      -0.021801  \n",
       "4845      -0.046788       0.039337  \n",
       "\n",
       "[4846 rows x 384 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b99e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df[\"Sentiment\"] = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99717512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_376</th>\n",
       "      <th>embedding_377</th>\n",
       "      <th>embedding_378</th>\n",
       "      <th>embedding_379</th>\n",
       "      <th>embedding_380</th>\n",
       "      <th>embedding_381</th>\n",
       "      <th>embedding_382</th>\n",
       "      <th>embedding_383</th>\n",
       "      <th>embedding_384</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033103</td>\n",
       "      <td>-0.100423</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>-0.066260</td>\n",
       "      <td>0.018836</td>\n",
       "      <td>-0.031824</td>\n",
       "      <td>-0.035340</td>\n",
       "      <td>-0.077344</td>\n",
       "      <td>-0.009411</td>\n",
       "      <td>-0.007487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069428</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>-0.089813</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>-0.019637</td>\n",
       "      <td>-0.018754</td>\n",
       "      <td>-0.127873</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>-0.022025</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084485</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>-0.002329</td>\n",
       "      <td>-0.056259</td>\n",
       "      <td>-0.113815</td>\n",
       "      <td>-0.121623</td>\n",
       "      <td>-0.061220</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>-0.064939</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>-0.040411</td>\n",
       "      <td>-0.021518</td>\n",
       "      <td>-0.055036</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>-0.034406</td>\n",
       "      <td>0.047268</td>\n",
       "      <td>0.056127</td>\n",
       "      <td>-0.001998</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043609</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.040851</td>\n",
       "      <td>-0.046114</td>\n",
       "      <td>0.062376</td>\n",
       "      <td>-0.028048</td>\n",
       "      <td>-0.046857</td>\n",
       "      <td>-0.038051</td>\n",
       "      <td>-0.068427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097364</td>\n",
       "      <td>0.010314</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>-0.012047</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>0.020335</td>\n",
       "      <td>0.038261</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067166</td>\n",
       "      <td>-0.029139</td>\n",
       "      <td>-0.037931</td>\n",
       "      <td>-0.010632</td>\n",
       "      <td>0.047564</td>\n",
       "      <td>-0.011515</td>\n",
       "      <td>-0.073900</td>\n",
       "      <td>0.040631</td>\n",
       "      <td>-0.057157</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043284</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.050133</td>\n",
       "      <td>-0.001276</td>\n",
       "      <td>0.048531</td>\n",
       "      <td>-0.034414</td>\n",
       "      <td>-0.071167</td>\n",
       "      <td>0.079625</td>\n",
       "      <td>-0.017603</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.021902</td>\n",
       "      <td>-0.022826</td>\n",
       "      <td>0.011935</td>\n",
       "      <td>-0.058745</td>\n",
       "      <td>-0.037734</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-0.022633</td>\n",
       "      <td>0.066558</td>\n",
       "      <td>-0.011591</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047741</td>\n",
       "      <td>-0.072852</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.062899</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>-0.126716</td>\n",
       "      <td>-0.077100</td>\n",
       "      <td>0.065531</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0     0.033103    -0.100423    -0.005485    -0.066260     0.018836   \n",
       "1     0.084485     0.030830    -0.002329    -0.056259    -0.113815   \n",
       "2     0.043609     0.004894     0.004905     0.040851    -0.046114   \n",
       "3    -0.067166    -0.029139    -0.037931    -0.010632     0.047564   \n",
       "4    -0.021902    -0.022826     0.011935    -0.058745    -0.037734   \n",
       "\n",
       "   embedding_6  embedding_7  embedding_8  embedding_9  embedding_10  ...  \\\n",
       "0    -0.031824    -0.035340    -0.077344    -0.009411     -0.007487  ...   \n",
       "1    -0.121623    -0.061220     0.055847    -0.064939      0.021643  ...   \n",
       "2     0.062376    -0.028048    -0.046857    -0.038051     -0.068427  ...   \n",
       "3    -0.011515    -0.073900     0.040631    -0.057157      0.001864  ...   \n",
       "4     0.007767    -0.022633     0.066558    -0.011591      0.004221  ...   \n",
       "\n",
       "   embedding_376  embedding_377  embedding_378  embedding_379  embedding_380  \\\n",
       "0       0.069428       0.011990      -0.089813       0.018476      -0.019637   \n",
       "1       0.006366      -0.040411      -0.021518      -0.055036       0.037341   \n",
       "2      -0.097364       0.010314       0.016644       0.062900      -0.012047   \n",
       "3       0.043284      -0.001184       0.050133      -0.001276       0.048531   \n",
       "4      -0.047741      -0.072852      -0.009161       0.004916       0.062899   \n",
       "\n",
       "   embedding_381  embedding_382  embedding_383  embedding_384  Sentiment  \n",
       "0      -0.018754      -0.127873       0.009407      -0.022025    neutral  \n",
       "1      -0.034406       0.047268       0.056127      -0.001998    neutral  \n",
       "2      -0.049860      -0.020716       0.020335       0.038261   negative  \n",
       "3      -0.034414      -0.071167       0.079625      -0.017603   positive  \n",
       "4       0.002259      -0.126716      -0.077100       0.065531   positive  \n",
       "\n",
       "[5 rows x 385 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d05ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embedding_df.drop([\"Sentiment\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2019be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = embedding_df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3972d571",
   "metadata": {},
   "source": [
    "# Label encoding predictor variable (sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "911954f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e74a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9d2655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = lbe.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9cd0fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d38d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d2b3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1363"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_encoded == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b1931b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2879"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_encoded == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b86cc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_encoded == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099e75b",
   "metadata": {},
   "source": [
    "# Stratified train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bdf231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handlingimbalanced dataset (Ex: churn prediction, device failure, cancer prediction)\n",
    "#https://www.youtube.com/watch?v=JnlM4yLFNuo\n",
    "# 1. undersampling majority class\n",
    "# 2. oversampling minority class by duplication\n",
    "# 3. oversampling minority class by SMOTE (synthetic examples using k nearest neighbors)\n",
    "# 4. ensemble (3000 in class 1 and 1000 in class 2, create three models with 1000 in each class and then \n",
    "#take majority vote of predictions made by the 3 models)\n",
    "# 5. focal loss (penalize majority class during loss calculation and give more weight to minority class samples)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c9b350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132     positive\n",
       "1189     neutral\n",
       "798     positive\n",
       "2000    positive\n",
       "3488     neutral\n",
       "          ...   \n",
       "1840     neutral\n",
       "1129    positive\n",
       "1682     neutral\n",
       "1016     neutral\n",
       "3477     neutral\n",
       "Name: Sentiment, Length: 3876, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222fbe33",
   "metadata": {},
   "source": [
    "# Decision Tree, Random Forest, Finetuning with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd045f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5639175257731959\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.43      0.45      0.44       121\n",
      "     neutral       0.68      0.67      0.67       576\n",
      "    positive       0.39      0.39      0.39       273\n",
      "\n",
      "    accuracy                           0.56       970\n",
      "   macro avg       0.50      0.50      0.50       970\n",
      "weighted avg       0.57      0.56      0.56       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d829b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7103092783505155\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.46      0.59       121\n",
      "     neutral       0.69      0.98      0.81       576\n",
      "    positive       0.85      0.25      0.39       273\n",
      "\n",
      "    accuracy                           0.71       970\n",
      "   macro avg       0.78      0.56      0.59       970\n",
      "weighted avg       0.75      0.71      0.66       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(class_weight='balanced', random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "337410f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavraahul/anaconda3/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is amazing\"\n",
    "emb = model.encode(text)\n",
    "clf.predict(emb.reshape(1,-1))[0]\n",
    "#In summary, (1, -1) is used when you want to reshape your array to have one row \n",
    "#and the number of columns inferred based on the size of the original array. \n",
    "#It doesn't transpose the array; it just changes its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd530567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4e3ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    \"random_state\": [5,10,20,30,40,50],\n",
    "    \"max_depth\": [2,5,10,20,50],\n",
    "    \"min_samples_split\": [2,5,10],\n",
    "    \"min_samples_leaf\": [1,2,4],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'class_weight': ['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cee016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scorer = make_scorer(accuracy_score)\n",
    "random_search = RandomizedSearchCV(estimator = rf_classifier, param_distributions = param_grid, cv = 3, scoring = custom_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc882d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_depth&#x27;: [2, 5, 10, 20, 50],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200],\n",
       "                                        &#x27;random_state&#x27;: [5, 10, 20, 30, 40,\n",
       "                                                         50]},\n",
       "                   scoring=make_scorer(accuracy_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_depth&#x27;: [2, 5, 10, 20, 50],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200],\n",
       "                                        &#x27;random_state&#x27;: [5, 10, 20, 30, 40,\n",
       "                                                         50]},\n",
       "                   scoring=make_scorer(accuracy_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'max_depth': [2, 5, 10, 20, 50],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [50, 100, 200],\n",
       "                                        'random_state': [5, 10, 20, 30, 40,\n",
       "                                                         50]},\n",
       "                   scoring=make_scorer(accuracy_score))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f6008d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b205a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a64080a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7381443298969073\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7d33860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 20,\n",
       " 'n_estimators': 200,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': 10,\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfdda362",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_2 = RandomForestClassifier()\n",
    "param_grid_2 = {\n",
    "    \"random_state\": [20,25,30,35],\n",
    "    \"max_depth\": [15,20,25],\n",
    "    \"min_samples_split\": [5,10, 15],\n",
    "    \"min_samples_leaf\": [1,2,3],\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'class_weight': ['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ab51235",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_2 = RandomizedSearchCV(estimator = rf_classifier_2, param_distributions = param_grid_2, cv = 3, scoring = custom_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27750205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_depth&#x27;: [15, 20, 25],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_split&#x27;: [5, 10, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [150, 200, 250],\n",
       "                                        &#x27;random_state&#x27;: [20, 25, 30, 35]},\n",
       "                   scoring=make_scorer(accuracy_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_depth&#x27;: [15, 20, 25],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_split&#x27;: [5, 10, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [150, 200, 250],\n",
       "                                        &#x27;random_state&#x27;: [20, 25, 30, 35]},\n",
       "                   scoring=make_scorer(accuracy_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'max_depth': [15, 20, 25],\n",
       "                                        'min_samples_leaf': [1, 2, 3],\n",
       "                                        'min_samples_split': [5, 10, 15],\n",
       "                                        'n_estimators': [150, 200, 250],\n",
       "                                        'random_state': [20, 25, 30, 35]},\n",
       "                   scoring=make_scorer(accuracy_score))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c476eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7309278350515463\n"
     ]
    }
   ],
   "source": [
    "best_params_2 = random_search_2.best_params_\n",
    "best_model_2 = random_search_2.best_estimator_\n",
    "y_pred_2 = best_model_2.predict(X_test)\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
    "print(\"Accuracy:\", accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dd74c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 25,\n",
       " 'n_estimators': 200,\n",
       " 'min_samples_split': 15,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_depth': 25,\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "833fd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = embedding_df[embedding_df[\"Sentiment\"] == \"positive\"]\n",
    "neutral = embedding_df[embedding_df[\"Sentiment\"] == \"neutral\"]\n",
    "negative = embedding_df[embedding_df[\"Sentiment\"] == \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "319193af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 385)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0af22320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(604, 385)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ba6451f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2879, 385)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a8e2dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 385)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a632e674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3876, 384)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58912c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2303\n",
       "positive    1090\n",
       "negative     483\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c5a3102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970, 384)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc082aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4840, 385)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rows_embedding_df = embedding_df.drop_duplicates()\n",
    "unique_rows_embedding_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ae85c",
   "metadata": {},
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3192230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows_each_class = int(min(positive.shape[0], neutral.shape[0], negative.shape[0])*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffc122b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positive = positive.sample(train_rows_each_class)\n",
    "train_neutral = neutral.sample(train_rows_each_class)\n",
    "train_negative = negative.sample(train_rows_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81bf2277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449, 385)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train_positive, train_neutral, train_negative], axis = 0)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08432061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.concat([embedding_df, train]).drop_duplicates(keep=False)\n",
    "test = pd.merge(embedding_df, train, how='left', indicator=True)\n",
    "test = test[test['_merge'] == 'left_only'].drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28650b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3397, 385)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd809bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsampling to understand class imbalance\n",
    "x_train = train.drop([\"Sentiment\"], axis = 1)\n",
    "Y_train = train[\"Sentiment\"]\n",
    "x_test = test.drop([\"Sentiment\"], axis = 1)\n",
    "Y_test = test[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba2fbd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_3 = RandomForestClassifier()\n",
    "param_grid_3 = {\n",
    "    \"random_state\": [20,25,30,35],\n",
    "    \"max_depth\": [15,20,25],\n",
    "    \"min_samples_split\": [5,10, 15],\n",
    "    \"min_samples_leaf\": [1,2,3],\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'class_weight': ['balanced', None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e82ad965",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search_3 = RandomizedSearchCV(estimator = rf_classifier_3, param_distributions = param_grid_3, cv = 5, scoring = custom_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01cbf4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_depth&#x27;: [15, 20, 25],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_split&#x27;: [5, 10, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [150, 200, 250],\n",
       "                                        &#x27;random_state&#x27;: [20, 25, 30, 35]},\n",
       "                   scoring=make_scorer(accuracy_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;max_depth&#x27;: [15, 20, 25],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_split&#x27;: [5, 10, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [150, 200, 250],\n",
       "                                        &#x27;random_state&#x27;: [20, 25, 30, 35]},\n",
       "                   scoring=make_scorer(accuracy_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'max_depth': [15, 20, 25],\n",
       "                                        'min_samples_leaf': [1, 2, 3],\n",
       "                                        'min_samples_split': [5, 10, 15],\n",
       "                                        'n_estimators': [150, 200, 250],\n",
       "                                        'random_state': [20, 25, 30, 35]},\n",
       "                   scoring=make_scorer(accuracy_score))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_3.fit(x_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62db913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7282896673535473\n"
     ]
    }
   ],
   "source": [
    "best_params_3 = random_search_3.best_params_\n",
    "best_model_3 = random_search_3.best_estimator_\n",
    "y_pred_3 = best_model_3.predict(x_test)\n",
    "accuracy_3 = accuracy_score(Y_test, y_pred_3)\n",
    "print(\"Accuracy:\", accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7c513bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 30,\n",
       " 'n_estimators': 250,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_depth': 15,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89204c",
   "metadata": {},
   "source": [
    "# Oversampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d35af814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#over_sampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9b627ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d521aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_4 = RandomForestClassifier(random_state = 20, n_estimators = 200, min_samples_split = 15, min_samples_leaf = 1, max_depth = 20,class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca2699c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6909, 384)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69dbe6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    2303\n",
       "neutral     2303\n",
       "negative    2303\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0e915446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7577319587628866\n"
     ]
    }
   ],
   "source": [
    "rf_classifier_4.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_4 = rf_classifier_4.predict(X_test)\n",
    "accuracy_4 = accuracy_score(y_test, y_pred_4)\n",
    "print(\"Accuracy:\", accuracy_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78d09e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report SMOTE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.68      0.70       121\n",
      "     neutral       0.77      0.91      0.83       576\n",
      "    positive       0.75      0.48      0.58       273\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.75      0.69      0.71       970\n",
      "weighted avg       0.76      0.76      0.74       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report SMOTE\")\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72a59753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Downsampling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.28      0.76      0.41       121\n",
      "     neutral       0.86      0.79      0.82      2396\n",
      "    positive       0.57      0.56      0.57       880\n",
      "\n",
      "    accuracy                           0.73      3397\n",
      "   macro avg       0.57      0.70      0.60      3397\n",
      "weighted avg       0.76      0.73      0.74      3397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report Downsampling\")\n",
    "print(classification_report(Y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9fb1f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Random Forest with RandomizedSearchCV)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.56      0.64       121\n",
      "     neutral       0.72      0.95      0.82       576\n",
      "    positive       0.78      0.34      0.48       273\n",
      "\n",
      "    accuracy                           0.73       970\n",
      "   macro avg       0.75      0.62      0.64       970\n",
      "weighted avg       0.74      0.73      0.70       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report (Random Forest with RandomizedSearchCV)\")\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df3bba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9809a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 68,  47,   6],\n",
       "       [  9, 547,  20],\n",
       "       [ 16, 163,  94]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4bb82dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 82,  33,   6],\n",
       "       [ 16, 522,  38],\n",
       "       [ 15, 127, 131]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f1a2778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7577319587628866"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85c85f1",
   "metadata": {},
   "source": [
    "# RNN (specifically LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bcc2ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Sample data (X: text sequences, y: sentiment labels)\n",
    "y_RNN = lbe.fit_transform(embedding_df['Sentiment'])\n",
    "X_RNN = df['News']\n",
    "\n",
    "X_train_RNN, X_test_RNN, y_train_RNN, y_test_RNN = train_test_split(X_RNN, y_RNN, test_size=0.2, random_state=42, stratify = y)\n",
    "\n",
    "\n",
    "# Tokenize words and convert to numerical sequences\n",
    "tokenizer = Tokenizer() #initialize tokenizer\n",
    "tokenizer.fit_on_texts(X_train_RNN) # processes the input text data (X_train_RNN) and updates the internal vocabulary based on the unique words present in the text.\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_RNN) # convert text to sequences\n",
    "\n",
    "# Pad sequences to fix input length to length 50\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=50, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce2371",
   "metadata": {},
   "source": [
    "# Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f681d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 2s 17ms/step - loss: -6.1032 - accuracy: 0.5890 - val_loss: -16.8009 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -52.2425 - accuracy: 0.5910 - val_loss: -93.6040 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -203.6387 - accuracy: 0.5910 - val_loss: -294.3900 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -532.1296 - accuracy: 0.5910 - val_loss: -667.8640 - val_accuracy: 0.6070\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -1074.3650 - accuracy: 0.5910 - val_loss: -1263.4275 - val_accuracy: 0.6070\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 2s 17ms/step - loss: -1903.2515 - accuracy: 0.5910 - val_loss: -2156.9338 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -3345.7905 - accuracy: 0.5903 - val_loss: -3453.8718 - val_accuracy: 0.6070\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 2s 17ms/step - loss: -5808.6201 - accuracy: 0.5906 - val_loss: -6280.3350 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -10481.7100 - accuracy: 0.5884 - val_loss: -7505.4795 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -14831.9326 - accuracy: 0.5910 - val_loss: -11782.3906 - val_accuracy: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17ddf0150>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "# (Assuming you have test data X_test and y_test prepared in a similar way as training data)\n",
    "# X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "# X_test_pad = pad_sequences(X_test_seq, maxlen=50, padding='post')\n",
    "# model.evaluate(X_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a153fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3876, 50)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb44871b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3876,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_RNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "31e588b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,  331, 2430,  112,  122,  807,  576,   25,   19,   48,   38,\n",
       "         95,  417,  147,   32,    5, 1777, 1395,   27, 1778,   13, 2431,\n",
       "       2023,   27, 1778,    3,  295,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2565f249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_RNN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5ae9600a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'in': 3,\n",
       " 'and': 4,\n",
       " 'to': 5,\n",
       " 'a': 6,\n",
       " 'for': 7,\n",
       " \"'s\": 8,\n",
       " 'eur': 9,\n",
       " 'is': 10,\n",
       " 'company': 11,\n",
       " 'will': 12,\n",
       " 'from': 13,\n",
       " 'on': 14,\n",
       " 'its': 15,\n",
       " 'with': 16,\n",
       " 'as': 17,\n",
       " 'has': 18,\n",
       " 'by': 19,\n",
       " 'be': 20,\n",
       " 'said': 21,\n",
       " 'mn': 22,\n",
       " 'finnish': 23,\n",
       " '1': 24,\n",
       " 'sales': 25,\n",
       " 'at': 26,\n",
       " 'million': 27,\n",
       " 'it': 28,\n",
       " 'that': 29,\n",
       " 'net': 30,\n",
       " 'profit': 31,\n",
       " 'year': 32,\n",
       " 'was': 33,\n",
       " 'm': 34,\n",
       " 'finland': 35,\n",
       " '2': 36,\n",
       " 'group': 37,\n",
       " '5': 38,\n",
       " '3': 39,\n",
       " 'an': 40,\n",
       " '2009': 41,\n",
       " 'operating': 42,\n",
       " '2008': 43,\n",
       " 'are': 44,\n",
       " '0': 45,\n",
       " 'business': 46,\n",
       " 'new': 47,\n",
       " '4': 48,\n",
       " 'period': 49,\n",
       " 'mln': 50,\n",
       " 'quarter': 51,\n",
       " '2010': 52,\n",
       " '6': 53,\n",
       " 'oyj': 54,\n",
       " '2007': 55,\n",
       " '7': 56,\n",
       " 'which': 57,\n",
       " 'have': 58,\n",
       " 'services': 59,\n",
       " \"''\": 60,\n",
       " 'market': 61,\n",
       " 'also': 62,\n",
       " '8': 63,\n",
       " '000': 64,\n",
       " 'share': 65,\n",
       " '9': 66,\n",
       " 'first': 67,\n",
       " 'this': 68,\n",
       " '2006': 69,\n",
       " 'up': 70,\n",
       " 'shares': 71,\n",
       " 'helsinki': 72,\n",
       " 'euro': 73,\n",
       " 'today': 74,\n",
       " 'been': 75,\n",
       " 'about': 76,\n",
       " 'mobile': 77,\n",
       " 'loss': 78,\n",
       " 'operations': 79,\n",
       " 'compared': 80,\n",
       " 'total': 81,\n",
       " 'contract': 82,\n",
       " '10': 83,\n",
       " 'corporation': 84,\n",
       " 'production': 85,\n",
       " 'financial': 86,\n",
       " 'based': 87,\n",
       " 'products': 88,\n",
       " 'we': 89,\n",
       " 'nokia': 90,\n",
       " 'technology': 91,\n",
       " 'than': 92,\n",
       " 'service': 93,\n",
       " 'bank': 94,\n",
       " 'per': 95,\n",
       " 'solutions': 96,\n",
       " 'were': 97,\n",
       " 'our': 98,\n",
       " 'companies': 99,\n",
       " 'corresponding': 100,\n",
       " 'percent': 101,\n",
       " 'plant': 102,\n",
       " 'well': 103,\n",
       " 'customers': 104,\n",
       " 'according': 105,\n",
       " 'hel': 106,\n",
       " 'other': 107,\n",
       " 'value': 108,\n",
       " 'one': 109,\n",
       " 'more': 110,\n",
       " 'not': 111,\n",
       " 'increased': 112,\n",
       " 'capital': 113,\n",
       " 'construction': 114,\n",
       " 'investment': 115,\n",
       " \"'\": 116,\n",
       " '2005': 117,\n",
       " 'increase': 118,\n",
       " 'agreement': 119,\n",
       " 'oy': 120,\n",
       " 'rose': 121,\n",
       " 'their': 122,\n",
       " 'some': 123,\n",
       " 'down': 124,\n",
       " 'all': 125,\n",
       " 'unit': 126,\n",
       " 'or': 127,\n",
       " 'order': 128,\n",
       " 'development': 129,\n",
       " 'would': 130,\n",
       " 'two': 131,\n",
       " 'january': 132,\n",
       " 's': 133,\n",
       " '30': 134,\n",
       " 'management': 135,\n",
       " 'over': 136,\n",
       " 'part': 137,\n",
       " 'stock': 138,\n",
       " 'pct': 139,\n",
       " 'industry': 140,\n",
       " '12': 141,\n",
       " 'building': 142,\n",
       " 'earlier': 143,\n",
       " 'end': 144,\n",
       " 'omx': 145,\n",
       " 'project': 146,\n",
       " 'last': 147,\n",
       " 'second': 148,\n",
       " '20': 149,\n",
       " 'expected': 150,\n",
       " 'into': 151,\n",
       " 'board': 152,\n",
       " 'paper': 153,\n",
       " 'after': 154,\n",
       " 'september': 155,\n",
       " 'ceo': 156,\n",
       " 'software': 157,\n",
       " 'employees': 158,\n",
       " 'deal': 159,\n",
       " 'same': 160,\n",
       " 'result': 161,\n",
       " 'russia': 162,\n",
       " 'signed': 163,\n",
       " 'equipment': 164,\n",
       " 'systems': 165,\n",
       " '11': 166,\n",
       " 'had': 167,\n",
       " '2011': 168,\n",
       " '15': 169,\n",
       " 'annual': 170,\n",
       " 'plc': 171,\n",
       " 'can': 172,\n",
       " 'media': 173,\n",
       " 'decreased': 174,\n",
       " 'price': 175,\n",
       " 'usd': 176,\n",
       " 'news': 177,\n",
       " 'third': 178,\n",
       " 'maker': 179,\n",
       " 'real': 180,\n",
       " 'under': 181,\n",
       " 'announced': 182,\n",
       " 'exchange': 183,\n",
       " 'area': 184,\n",
       " 'billion': 185,\n",
       " '14': 186,\n",
       " 'data': 187,\n",
       " 'both': 188,\n",
       " 'including': 189,\n",
       " 'may': 190,\n",
       " 'global': 191,\n",
       " 'product': 192,\n",
       " 'june': 193,\n",
       " 'system': 194,\n",
       " 'approximately': 195,\n",
       " 'people': 196,\n",
       " 'markets': 197,\n",
       " 'number': 198,\n",
       " 'now': 199,\n",
       " 'use': 200,\n",
       " 'report': 201,\n",
       " 'acquisition': 202,\n",
       " 'us': 203,\n",
       " 'before': 204,\n",
       " 'long': 205,\n",
       " 'design': 206,\n",
       " 'while': 207,\n",
       " '25': 208,\n",
       " 'he': 209,\n",
       " 'countries': 210,\n",
       " 'between': 211,\n",
       " 'during': 212,\n",
       " 'euros': 213,\n",
       " 'however': 214,\n",
       " 'october': 215,\n",
       " '13': 216,\n",
       " 'line': 217,\n",
       " 'ltd': 218,\n",
       " 'most': 219,\n",
       " 'time': 220,\n",
       " 'growth': 221,\n",
       " 'through': 222,\n",
       " 'months': 223,\n",
       " 'network': 224,\n",
       " 'april': 225,\n",
       " 'largest': 226,\n",
       " 'out': 227,\n",
       " 'march': 228,\n",
       " 'swedish': 229,\n",
       " 'they': 230,\n",
       " 'energy': 231,\n",
       " 'eur0': 232,\n",
       " 'supply': 233,\n",
       " 'these': 234,\n",
       " 'include': 235,\n",
       " 'electronics': 236,\n",
       " 'release': 237,\n",
       " 'no': 238,\n",
       " 'steel': 239,\n",
       " 'years': 240,\n",
       " 'information': 241,\n",
       " 'engineering': 242,\n",
       " 'stake': 243,\n",
       " '19': 244,\n",
       " 'manufacturing': 245,\n",
       " 'half': 246,\n",
       " '18': 247,\n",
       " 'nordic': 248,\n",
       " 'subsidiary': 249,\n",
       " 'totaled': 250,\n",
       " 'sale': 251,\n",
       " 'high': 252,\n",
       " 'manufacturer': 253,\n",
       " '16': 254,\n",
       " 'month': 255,\n",
       " 'earnings': 256,\n",
       " 'sector': 257,\n",
       " 'february': 258,\n",
       " 'includes': 259,\n",
       " 'three': 260,\n",
       " 'fell': 261,\n",
       " 'negotiations': 262,\n",
       " 'office': 263,\n",
       " 'cash': 264,\n",
       " '50': 265,\n",
       " 'expects': 266,\n",
       " 'rights': 267,\n",
       " 'reported': 268,\n",
       " 'world': 269,\n",
       " 'further': 270,\n",
       " 'revenue': 271,\n",
       " 'estimated': 272,\n",
       " 'president': 273,\n",
       " 'made': 274,\n",
       " '17': 275,\n",
       " 'ruukki': 276,\n",
       " 'non': 277,\n",
       " 'industrial': 278,\n",
       " 'term': 279,\n",
       " 'machinery': 280,\n",
       " 'baltic': 281,\n",
       " 'international': 282,\n",
       " 'process': 283,\n",
       " 'food': 284,\n",
       " 'transaction': 285,\n",
       " 'totalled': 286,\n",
       " 'start': 287,\n",
       " '40': 288,\n",
       " 'such': 289,\n",
       " 'related': 290,\n",
       " 'power': 291,\n",
       " 'phone': 292,\n",
       " 'capacity': 293,\n",
       " 'china': 294,\n",
       " '2004': 295,\n",
       " 'capman': 296,\n",
       " 'completed': 297,\n",
       " 'oil': 298,\n",
       " 'says': 299,\n",
       " 'when': 300,\n",
       " 'eps': 301,\n",
       " 'local': 302,\n",
       " 'lower': 303,\n",
       " 'orders': 304,\n",
       " 'significant': 305,\n",
       " 'solution': 306,\n",
       " 'july': 307,\n",
       " 'networks': 308,\n",
       " 'customer': 309,\n",
       " '100': 310,\n",
       " '35': 311,\n",
       " 'off': 312,\n",
       " 'cost': 313,\n",
       " 'director': 314,\n",
       " 'stora': 315,\n",
       " 'sweden': 316,\n",
       " 'supplier': 317,\n",
       " 'six': 318,\n",
       " 'nine': 319,\n",
       " 'units': 320,\n",
       " '26': 321,\n",
       " 'prices': 322,\n",
       " 'around': 323,\n",
       " 'leading': 324,\n",
       " 'developed': 325,\n",
       " 'facility': 326,\n",
       " 'projects': 327,\n",
       " 'august': 328,\n",
       " 'elcoteq': 329,\n",
       " 'his': 330,\n",
       " 'major': 331,\n",
       " 'distribution': 332,\n",
       " 'enso': 333,\n",
       " 'inc': 334,\n",
       " 'insurance': 335,\n",
       " 'full': 336,\n",
       " 'due': 337,\n",
       " 'nordea': 338,\n",
       " 'strategy': 339,\n",
       " 'day': 340,\n",
       " 'set': 341,\n",
       " 'europe': 342,\n",
       " 'upm': 343,\n",
       " '21': 344,\n",
       " 'personnel': 345,\n",
       " 'basware': 346,\n",
       " 'yit': 347,\n",
       " 'communications': 348,\n",
       " 'fourth': 349,\n",
       " 'internet': 350,\n",
       " 'division': 351,\n",
       " 'since': 352,\n",
       " 'russian': 353,\n",
       " '29': 354,\n",
       " 'currently': 355,\n",
       " 'addition': 356,\n",
       " 'fiskars': 357,\n",
       " 'turnover': 358,\n",
       " 'provider': 359,\n",
       " 'next': 360,\n",
       " 'range': 361,\n",
       " 'center': 362,\n",
       " 'used': 363,\n",
       " 'already': 364,\n",
       " 'brand': 365,\n",
       " 'offer': 366,\n",
       " 'issue': 367,\n",
       " 'previously': 368,\n",
       " 'sell': 369,\n",
       " 'agreed': 370,\n",
       " 'added': 371,\n",
       " 'results': 372,\n",
       " '27': 373,\n",
       " '24': 374,\n",
       " 'corp': 375,\n",
       " 'north': 376,\n",
       " 'america': 377,\n",
       " 'handling': 378,\n",
       " 'mr': 379,\n",
       " 'option': 380,\n",
       " 'l': 381,\n",
       " 'retail': 382,\n",
       " 'traffic': 383,\n",
       " 'processing': 384,\n",
       " 'target': 385,\n",
       " 'provide': 386,\n",
       " 'general': 387,\n",
       " 'estate': 388,\n",
       " '22': 389,\n",
       " 'program': 390,\n",
       " 'support': 391,\n",
       " 'position': 392,\n",
       " 'amounted': 393,\n",
       " 'available': 394,\n",
       " 'four': 395,\n",
       " 'areas': 396,\n",
       " 'sold': 397,\n",
       " 'city': 398,\n",
       " 'december': 399,\n",
       " 'purchase': 400,\n",
       " 'cooperation': 401,\n",
       " 'via': 402,\n",
       " 'following': 403,\n",
       " 'acquired': 404,\n",
       " 'won': 405,\n",
       " 'grew': 406,\n",
       " 'chain': 407,\n",
       " 'headquartered': 408,\n",
       " 'firm': 409,\n",
       " 'provides': 410,\n",
       " 'pulp': 411,\n",
       " 'credit': 412,\n",
       " '23': 413,\n",
       " 'awarded': 414,\n",
       " 'chairman': 415,\n",
       " 'volume': 416,\n",
       " 'cent': 417,\n",
       " 'device': 418,\n",
       " 'aspo': 419,\n",
       " 'buy': 420,\n",
       " 'st': 421,\n",
       " 'items': 422,\n",
       " 'level': 423,\n",
       " 'quality': 424,\n",
       " 'directors': 425,\n",
       " 'alma': 426,\n",
       " '200': 427,\n",
       " 'november': 428,\n",
       " 'com': 429,\n",
       " 'where': 430,\n",
       " 'online': 431,\n",
       " 'there': 432,\n",
       " 'rental': 433,\n",
       " 'life': 434,\n",
       " 'shareholders': 435,\n",
       " 'friday': 436,\n",
       " 'costs': 437,\n",
       " 'secure': 438,\n",
       " '33': 439,\n",
       " 'region': 440,\n",
       " 'security': 441,\n",
       " 'applications': 442,\n",
       " 'margin': 443,\n",
       " 'european': 444,\n",
       " 'current': 445,\n",
       " 'received': 446,\n",
       " 'situation': 447,\n",
       " 'take': 448,\n",
       " 'launch': 449,\n",
       " 'fixed': 450,\n",
       " 'maintenance': 451,\n",
       " 'make': 452,\n",
       " 'voting': 453,\n",
       " 'performance': 454,\n",
       " 'meeting': 455,\n",
       " 'logistics': 456,\n",
       " 'central': 457,\n",
       " 'very': 458,\n",
       " 'www': 459,\n",
       " 'delivered': 460,\n",
       " 'mill': 461,\n",
       " 'lay': 462,\n",
       " 'teleste': 463,\n",
       " 'continue': 464,\n",
       " 'developer': 465,\n",
       " 'plans': 466,\n",
       " 'plants': 467,\n",
       " '28': 468,\n",
       " 'research': 469,\n",
       " 'offering': 470,\n",
       " 'p': 471,\n",
       " 'co': 472,\n",
       " 'forest': 473,\n",
       " 'u': 474,\n",
       " 'estonia': 475,\n",
       " 'petersburg': 476,\n",
       " 'recurring': 477,\n",
       " 'only': 478,\n",
       " 'sampo': 479,\n",
       " 'store': 480,\n",
       " 'eur1': 481,\n",
       " 'using': 482,\n",
       " 'contracts': 483,\n",
       " 'trade': 484,\n",
       " 'ahlstrom': 485,\n",
       " 'reports': 486,\n",
       " 'materials': 487,\n",
       " 'savings': 488,\n",
       " 'transfer': 489,\n",
       " 'decision': 490,\n",
       " 'teliasonera': 491,\n",
       " 'content': 492,\n",
       " 'press': 493,\n",
       " 'base': 494,\n",
       " 'work': 495,\n",
       " 'uk': 496,\n",
       " 'previous': 497,\n",
       " 'finnair': 498,\n",
       " 'established': 499,\n",
       " 'sanoma': 500,\n",
       " 'kesko': 501,\n",
       " 'scheduled': 502,\n",
       " 'government': 503,\n",
       " 'ab': 504,\n",
       " 'own': 505,\n",
       " 'started': 506,\n",
       " 'being': 507,\n",
       " 'built': 508,\n",
       " 'stockmann': 509,\n",
       " 'kemira': 510,\n",
       " 'terms': 511,\n",
       " 'corporate': 512,\n",
       " 'who': 513,\n",
       " 'income': 514,\n",
       " '31': 515,\n",
       " 'higher': 516,\n",
       " 'large': 517,\n",
       " 'experience': 518,\n",
       " 'staff': 519,\n",
       " 'operation': 520,\n",
       " 'devices': 521,\n",
       " 'positive': 522,\n",
       " 'facilities': 523,\n",
       " 'flow': 524,\n",
       " 'future': 525,\n",
       " 'main': 526,\n",
       " 'operators': 527,\n",
       " 'strong': 528,\n",
       " 'partner': 529,\n",
       " 'amount': 530,\n",
       " 'focus': 531,\n",
       " 'marketing': 532,\n",
       " 'measures': 533,\n",
       " 'best': 534,\n",
       " 'delivery': 535,\n",
       " 'disclosed': 536,\n",
       " 'members': 537,\n",
       " 'germany': 538,\n",
       " 'glaston': 539,\n",
       " 'okmetic': 540,\n",
       " 'adp': 541,\n",
       " 'poyry': 542,\n",
       " 'index': 543,\n",
       " 'rapala': 544,\n",
       " 'i': 545,\n",
       " '80': 546,\n",
       " 'expand': 547,\n",
       " 'afx': 548,\n",
       " 'held': 549,\n",
       " 'taxes': 550,\n",
       " 'planning': 551,\n",
       " 'marimekko': 552,\n",
       " 'whole': 553,\n",
       " 'ago': 554,\n",
       " 'excluding': 555,\n",
       " 'wednesday': 556,\n",
       " 'gas': 557,\n",
       " 'application': 558,\n",
       " 'tikkurila': 559,\n",
       " 'investments': 560,\n",
       " 'chief': 561,\n",
       " 'scanfil': 562,\n",
       " 'water': 563,\n",
       " 'deliveries': 564,\n",
       " 'elisa': 565,\n",
       " 'pohjola': 566,\n",
       " 'metso': 567,\n",
       " 'posted': 568,\n",
       " 'them': 569,\n",
       " 'telecom': 570,\n",
       " 'owned': 571,\n",
       " 'incap': 572,\n",
       " 'tonnes': 573,\n",
       " 'employs': 574,\n",
       " 'making': 575,\n",
       " 'beer': 576,\n",
       " 'worth': 577,\n",
       " 'pharmaceutical': 578,\n",
       " 'analysis': 579,\n",
       " 'issued': 580,\n",
       " 'demand': 581,\n",
       " 'place': 582,\n",
       " 'consumers': 583,\n",
       " 'holding': 584,\n",
       " 'if': 585,\n",
       " 'head': 586,\n",
       " 'site': 587,\n",
       " 'neste': 588,\n",
       " 'portfolio': 589,\n",
       " 'infrastructure': 590,\n",
       " 'material': 591,\n",
       " 'phones': 592,\n",
       " 'details': 593,\n",
       " 'any': 594,\n",
       " 'b': 595,\n",
       " 'cover': 596,\n",
       " 'square': 597,\n",
       " 'respectively': 598,\n",
       " 'existing': 599,\n",
       " 'good': 600,\n",
       " 'video': 601,\n",
       " 'businesses': 602,\n",
       " 'joint': 603,\n",
       " 'state': 604,\n",
       " 'technologies': 605,\n",
       " 'activities': 606,\n",
       " 'sports': 607,\n",
       " 'combined': 608,\n",
       " 'managing': 609,\n",
       " 'handset': 610,\n",
       " 'but': 611,\n",
       " 'generated': 612,\n",
       " 'asia': 613,\n",
       " 'cut': 614,\n",
       " 'componenta': 615,\n",
       " 'atria': 616,\n",
       " 'provided': 617,\n",
       " 'poland': 618,\n",
       " 'commercial': 619,\n",
       " 'close': 620,\n",
       " 'improved': 621,\n",
       " 'packaging': 622,\n",
       " 'glass': 623,\n",
       " 'different': 624,\n",
       " 'stores': 625,\n",
       " 'konecranes': 626,\n",
       " 'become': 627,\n",
       " 'properties': 628,\n",
       " 'offers': 629,\n",
       " 'mid': 630,\n",
       " 'offs': 631,\n",
       " 'operator': 632,\n",
       " 'decided': 633,\n",
       " 'located': 634,\n",
       " 'electronic': 635,\n",
       " '60': 636,\n",
       " 'cargotec': 637,\n",
       " 'pretax': 638,\n",
       " 'manager': 639,\n",
       " 'property': 640,\n",
       " 'london': 641,\n",
       " 'control': 642,\n",
       " '00': 643,\n",
       " 'entire': 644,\n",
       " 'sq': 645,\n",
       " 'natural': 646,\n",
       " 'raw': 647,\n",
       " 'remain': 648,\n",
       " 'improve': 649,\n",
       " 'cramo': 650,\n",
       " '36': 651,\n",
       " 'move': 652,\n",
       " 'public': 653,\n",
       " 'resources': 654,\n",
       " '45': 655,\n",
       " 'outotec': 656,\n",
       " 'access': 657,\n",
       " 'went': 658,\n",
       " 'ramirent': 659,\n",
       " 'shipping': 660,\n",
       " 'interest': 661,\n",
       " 'covers': 662,\n",
       " 'five': 663,\n",
       " 'talvivaara': 664,\n",
       " 'printing': 665,\n",
       " 'estimates': 666,\n",
       " 'tuesday': 667,\n",
       " 'f': 668,\n",
       " 'rautaruukki': 669,\n",
       " 'owner': 670,\n",
       " 'continued': 671,\n",
       " 'bn': 672,\n",
       " '32': 673,\n",
       " 'back': 674,\n",
       " 'published': 675,\n",
       " 'developing': 676,\n",
       " 'fund': 677,\n",
       " 'makes': 678,\n",
       " 'listed': 679,\n",
       " 'within': 680,\n",
       " 'plan': 681,\n",
       " 'aspocomp': 682,\n",
       " 'pre': 683,\n",
       " 'patent': 684,\n",
       " 'consumer': 685,\n",
       " 'fair': 686,\n",
       " 'magazine': 687,\n",
       " '42': 688,\n",
       " 'executive': 689,\n",
       " 'investors': 690,\n",
       " 'raisio': 691,\n",
       " 'so': 692,\n",
       " 'segment': 693,\n",
       " 'slightly': 694,\n",
       " 'paid': 695,\n",
       " '38': 696,\n",
       " 'reporting': 697,\n",
       " 'maximum': 698,\n",
       " 'kymmene': 699,\n",
       " 'fully': 700,\n",
       " 'summer': 701,\n",
       " 'expansion': 702,\n",
       " 'tekla': 703,\n",
       " 'because': 704,\n",
       " 'operates': 705,\n",
       " 'strategic': 706,\n",
       " 'kone': 707,\n",
       " '43': 708,\n",
       " 'tools': 709,\n",
       " 'small': 710,\n",
       " 'broadband': 711,\n",
       " 'platform': 712,\n",
       " 'park': 713,\n",
       " 'invest': 714,\n",
       " 'aim': 715,\n",
       " 'key': 716,\n",
       " 'concerning': 717,\n",
       " 'beginning': 718,\n",
       " 'acquire': 719,\n",
       " 'present': 720,\n",
       " 'closed': 721,\n",
       " 'versus': 722,\n",
       " 'working': 723,\n",
       " 'trading': 724,\n",
       " 'several': 725,\n",
       " 'digital': 726,\n",
       " 'vice': 727,\n",
       " 'do': 728,\n",
       " 'industries': 729,\n",
       " 'home': 730,\n",
       " '70': 731,\n",
       " 'south': 732,\n",
       " 'administration': 733,\n",
       " 'planned': 734,\n",
       " 'e': 735,\n",
       " 'house': 736,\n",
       " 'effect': 737,\n",
       " 'low': 738,\n",
       " 'funds': 739,\n",
       " 'nasdaq': 740,\n",
       " 'dividend': 741,\n",
       " 'temporary': 742,\n",
       " 'outokumpu': 743,\n",
       " 'panostaja': 744,\n",
       " 'points': 745,\n",
       " 'agreements': 746,\n",
       " 'clients': 747,\n",
       " 'partners': 748,\n",
       " 'known': 749,\n",
       " 'enables': 750,\n",
       " 'few': 751,\n",
       " 'latest': 752,\n",
       " 'space': 753,\n",
       " 'liters': 754,\n",
       " 'providing': 755,\n",
       " 'lead': 756,\n",
       " 'siemens': 757,\n",
       " 'vaisala': 758,\n",
       " 'communication': 759,\n",
       " 'eur2': 760,\n",
       " 'carried': 761,\n",
       " 'another': 762,\n",
       " 'growing': 763,\n",
       " 'metal': 764,\n",
       " '500': 765,\n",
       " 'how': 766,\n",
       " 'outside': 767,\n",
       " 'r': 768,\n",
       " 'name': 769,\n",
       " 'shareholder': 770,\n",
       " 'telecommunications': 771,\n",
       " 'date': 772,\n",
       " 'alexandria': 773,\n",
       " 'va': 774,\n",
       " 'states': 775,\n",
       " '90': 776,\n",
       " 'changes': 777,\n",
       " 'meat': 778,\n",
       " 'india': 779,\n",
       " 'bring': 780,\n",
       " 'tax': 781,\n",
       " 'top': 782,\n",
       " 'machines': 783,\n",
       " 'just': 784,\n",
       " 'way': 785,\n",
       " 'aims': 786,\n",
       " 'banking': 787,\n",
       " 'france': 788,\n",
       " 'brands': 789,\n",
       " 'technopolis': 790,\n",
       " 'x20ac': 791,\n",
       " 'enable': 792,\n",
       " 'investor': 793,\n",
       " 'deliver': 794,\n",
       " 'consolidated': 795,\n",
       " 'comptel': 796,\n",
       " 'cencorp': 797,\n",
       " 'revenues': 798,\n",
       " '39': 799,\n",
       " 'responsible': 800,\n",
       " 'digia': 801,\n",
       " 'enterprise': 802,\n",
       " 'subscription': 803,\n",
       " 'you': 804,\n",
       " 'announcement': 805,\n",
       " 'change': 806,\n",
       " 'domestic': 807,\n",
       " 'assets': 808,\n",
       " 'fortum': 809,\n",
       " 'am': 810,\n",
       " 'thursday': 811,\n",
       " 'recently': 812,\n",
       " 'stockholm': 813,\n",
       " 'continuing': 814,\n",
       " 'economic': 815,\n",
       " 'holdings': 816,\n",
       " 'pay': 817,\n",
       " 'd': 818,\n",
       " 'persons': 819,\n",
       " 'able': 820,\n",
       " 'espoo': 821,\n",
       " 'efficiency': 822,\n",
       " 'offices': 823,\n",
       " 'biggest': 824,\n",
       " 'strengthen': 825,\n",
       " '48': 826,\n",
       " '37': 827,\n",
       " 'northern': 828,\n",
       " 'various': 829,\n",
       " 'selling': 830,\n",
       " 'suominen': 831,\n",
       " 'efficient': 832,\n",
       " 'factory': 833,\n",
       " 'machine': 834,\n",
       " 'web': 835,\n",
       " 'subscribed': 836,\n",
       " 'operational': 837,\n",
       " 'build': 838,\n",
       " 'method': 839,\n",
       " 'structure': 840,\n",
       " 'sponda': 841,\n",
       " 'venture': 842,\n",
       " 'automation': 843,\n",
       " 'your': 844,\n",
       " 'core': 845,\n",
       " 'lines': 846,\n",
       " 'structures': 847,\n",
       " 'country': 848,\n",
       " 'completion': 849,\n",
       " 'cargo': 850,\n",
       " 'department': 851,\n",
       " 'above': 852,\n",
       " 'statement': 853,\n",
       " 'talentum': 854,\n",
       " 'week': 855,\n",
       " 'narrowed': 856,\n",
       " 'forward': 857,\n",
       " 'levels': 858,\n",
       " 'yesterday': 859,\n",
       " 'voice': 860,\n",
       " 'develop': 861,\n",
       " 'ship': 862,\n",
       " 'uponor': 863,\n",
       " 'outlook': 864,\n",
       " 'waste': 865,\n",
       " 'social': 866,\n",
       " 'installation': 867,\n",
       " 'told': 868,\n",
       " 'users': 869,\n",
       " 'below': 870,\n",
       " 'jan': 871,\n",
       " 'land': 872,\n",
       " 'private': 873,\n",
       " 'banks': 874,\n",
       " 'eastern': 875,\n",
       " 'environment': 876,\n",
       " 'owns': 877,\n",
       " 'employment': 878,\n",
       " 'potential': 879,\n",
       " 'volumes': 880,\n",
       " 'starting': 881,\n",
       " 'options': 882,\n",
       " '3g': 883,\n",
       " 'norwegian': 884,\n",
       " 'transportation': 885,\n",
       " 'restructuring': 886,\n",
       " 'suomen': 887,\n",
       " 'member': 888,\n",
       " 'union': 889,\n",
       " 'included': 890,\n",
       " 'components': 891,\n",
       " 'salcomp': 892,\n",
       " 'approved': 893,\n",
       " 'impact': 894,\n",
       " 'what': 895,\n",
       " 'metres': 896,\n",
       " 'vaahto': 897,\n",
       " 'oct': 898,\n",
       " 'efore': 899,\n",
       " 'came': 900,\n",
       " 'daily': 901,\n",
       " 'rise': 902,\n",
       " '49': 903,\n",
       " 'cutting': 904,\n",
       " 't': 905,\n",
       " 'tallinn': 906,\n",
       " 'negative': 907,\n",
       " 'return': 908,\n",
       " 'music': 909,\n",
       " 'wood': 910,\n",
       " 'tons': 911,\n",
       " 'goods': 912,\n",
       " '150': 913,\n",
       " 'competition': 914,\n",
       " '47': 915,\n",
       " 'worldwide': 916,\n",
       " 'especially': 917,\n",
       " 'analyst': 918,\n",
       " 'shopping': 919,\n",
       " 'bridge': 920,\n",
       " 'location': 921,\n",
       " '55': 922,\n",
       " 'user': 923,\n",
       " 'loan': 924,\n",
       " '300': 925,\n",
       " 'wireless': 926,\n",
       " 'launched': 927,\n",
       " 'complete': 928,\n",
       " 'united': 929,\n",
       " 'then': 930,\n",
       " 'serve': 931,\n",
       " 'near': 932,\n",
       " 'analysts': 933,\n",
       " 'fuel': 934,\n",
       " 'affecto': 935,\n",
       " 'treatment': 936,\n",
       " 'rates': 937,\n",
       " 'papers': 938,\n",
       " 'declined': 939,\n",
       " 'later': 940,\n",
       " 'dropped': 941,\n",
       " 'viking': 942,\n",
       " 'usa': 943,\n",
       " 'norway': 944,\n",
       " 'czech': 945,\n",
       " 'without': 946,\n",
       " 'those': 947,\n",
       " 'registered': 948,\n",
       " 'register': 949,\n",
       " '51': 950,\n",
       " 'benefon': 951,\n",
       " 'manufacturers': 952,\n",
       " 'orion': 953,\n",
       " 'job': 954,\n",
       " 'airline': 955,\n",
       " 'africa': 956,\n",
       " 'special': 957,\n",
       " 'ebit': 958,\n",
       " 'pension': 959,\n",
       " 'does': 960,\n",
       " 'hand': 961,\n",
       " 'weeks': 962,\n",
       " 'cap': 963,\n",
       " 'produced': 964,\n",
       " 'producer': 965,\n",
       " 'fiscal': 966,\n",
       " 'estonian': 967,\n",
       " 'fall': 968,\n",
       " 'nyse': 969,\n",
       " 'personal': 970,\n",
       " 'stood': 971,\n",
       " 'statements': 972,\n",
       " 'much': 973,\n",
       " 'port': 974,\n",
       " 'right': 975,\n",
       " 'q1': 976,\n",
       " 'bought': 977,\n",
       " 'each': 978,\n",
       " 'indian': 979,\n",
       " 'jobs': 980,\n",
       " 'asset': 981,\n",
       " 'expertise': 982,\n",
       " 'know': 983,\n",
       " 'sek': 984,\n",
       " 'aktia': 985,\n",
       " 'pleased': 986,\n",
       " 'wide': 987,\n",
       " 'stainless': 988,\n",
       " 'silicon': 989,\n",
       " 'reduce': 990,\n",
       " 'accounted': 991,\n",
       " 'passenger': 992,\n",
       " 'overall': 993,\n",
       " 'autumn': 994,\n",
       " 'dec': 995,\n",
       " 'directed': 996,\n",
       " 'biohit': 997,\n",
       " 'gives': 998,\n",
       " 'managed': 999,\n",
       " 'safety': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78b2aa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9020"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f931b15",
   "metadata": {},
   "source": [
    "# Deeper model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5300272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -199.0300 - accuracy: 0.5865 - val_loss: -1170.1208 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -16916.6152 - accuracy: 0.5910 - val_loss: -53666.8086 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -257015.8594 - accuracy: 0.5910 - val_loss: -553755.5625 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -1523112.7500 - accuracy: 0.5910 - val_loss: -2545429.0000 - val_accuracy: 0.6070\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -6392094.5000 - accuracy: 0.5913 - val_loss: -9226776.0000 - val_accuracy: 0.6070\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -22601454.0000 - accuracy: 0.5916 - val_loss: -26948952.0000 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: -61571092.0000 - accuracy: 0.5884 - val_loss: -61193264.0000 - val_accuracy: 0.6070\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -143556736.0000 - accuracy: 0.5890 - val_loss: -122005632.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -291769888.0000 - accuracy: 0.5865 - val_loss: -254655520.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 1s 15ms/step - loss: -524226528.0000 - accuracy: 0.5871 - val_loss: -434247264.0000 - val_accuracy: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c83af010>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model2 = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ad32313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: -480226560.0000 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-480226560.0, 0.5938144326210022]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test_RNN)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=50, padding='post')\n",
    "model2.evaluate(X_test_pad, y_test_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b681fb",
   "metadata": {},
   "source": [
    "# Increased output_dim from 100 to 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13b0599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 3s 21ms/step - loss: -703.0923 - accuracy: 0.5910 - val_loss: -3762.5391 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 2s 19ms/step - loss: -61977.9727 - accuracy: 0.5910 - val_loss: -186081.2969 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 2s 19ms/step - loss: -817777.6250 - accuracy: 0.5910 - val_loss: -1712220.7500 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 2s 19ms/step - loss: -5045122.5000 - accuracy: 0.5910 - val_loss: -8850775.0000 - val_accuracy: 0.6070\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 2s 20ms/step - loss: -19492476.0000 - accuracy: 0.5910 - val_loss: -29431476.0000 - val_accuracy: 0.6070\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 2s 21ms/step - loss: -68151888.0000 - accuracy: 0.5910 - val_loss: -78255088.0000 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 2s 20ms/step - loss: -203839392.0000 - accuracy: 0.5861 - val_loss: -205726512.0000 - val_accuracy: 0.6070\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 2s 20ms/step - loss: -497532352.0000 - accuracy: 0.5797 - val_loss: -446363744.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 2s 21ms/step - loss: -1024588288.0000 - accuracy: 0.5813 - val_loss: -864142592.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 2s 20ms/step - loss: -1876446720.0000 - accuracy: 0.5800 - val_loss: -1546445440.0000 - val_accuracy: 0.6070\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model3 = Sequential([\n",
    "    #reducing vocab by reducing input_dim parameter\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=150, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model3.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6da27462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: -1789672320.0000 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1789672320.0, 0.5938144326210022]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test_pad, y_test_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d551d",
   "metadata": {},
   "source": [
    "# Increased output_dim from 100 to 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8b0c676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -287.3768 - accuracy: 0.5884 - val_loss: -1588.6335 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -24190.8379 - accuracy: 0.5910 - val_loss: -72264.1562 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 2s 24ms/step - loss: -362219.0938 - accuracy: 0.5910 - val_loss: -794775.9375 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -1480021.0000 - accuracy: 0.5910 - val_loss: 238968.2656 - val_accuracy: 0.6070\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -339232.1875 - accuracy: 0.5910 - val_loss: -79433.0859 - val_accuracy: 0.6070\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -914367.6875 - accuracy: 0.5910 - val_loss: -930403.5625 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 2s 26ms/step - loss: -4091935.0000 - accuracy: 0.5910 - val_loss: -7002363.5000 - val_accuracy: 0.6070\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 2s 24ms/step - loss: -20043158.0000 - accuracy: 0.5910 - val_loss: -29415854.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 2s 24ms/step - loss: -73480224.0000 - accuracy: 0.5910 - val_loss: -96402760.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 2s 24ms/step - loss: -223861280.0000 - accuracy: 0.6058 - val_loss: -247273600.0000 - val_accuracy: 0.6289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x30633af10>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model4 = Sequential([\n",
    "    #reducing vocab by reducing input_dim parameter\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model4.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5190a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: -264134672.0000 - accuracy: 0.6093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-264134672.0, 0.6092783212661743]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test_pad, y_test_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5a403",
   "metadata": {},
   "source": [
    "# Deeper model with output_dim set at 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "852cae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 3s 28ms/step - loss: -1010164.0000 - accuracy: 0.5900 - val_loss: -7749305.5000 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -874987136.0000 - accuracy: 0.5910 - val_loss: -4020476160.0000 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -49957097472.0000 - accuracy: 0.5910 - val_loss: -139808473088.0000 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -717175390208.0000 - accuracy: 0.5910 - val_loss: -1489453580288.0000 - val_accuracy: 0.6070\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -7681790181376.0000 - accuracy: 0.5832 - val_loss: -12135785562112.0000 - val_accuracy: 0.5992\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -44996405231616.0000 - accuracy: 0.5923 - val_loss: -59237476597760.0000 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -183510715334656.0000 - accuracy: 0.5926 - val_loss: -231047094599680.0000 - val_accuracy: 0.6070\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: -653764352540672.0000 - accuracy: 0.5826 - val_loss: -716553284747264.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -1864191765905408.0000 - accuracy: 0.5984 - val_loss: -1748275161989120.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: -4507509658222592.0000 - accuracy: 0.5913 - val_loss: -4317314547712000.0000 - val_accuracy: 0.5747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d30e44d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RNN model\n",
    "model5 = Sequential([\n",
    "    #reducing vocab by reducing input_dim parameter\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=300, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=1024, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model5.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80b14188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: -4824268865011712.0000 - accuracy: 0.5649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-4824268865011712.0, 0.5649484395980835]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(X_test_pad, y_test_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c57ae",
   "metadata": {},
   "source": [
    "# Increased output_dim from 100 to 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3e4c1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: -218.2769 - accuracy: 0.5868 - val_loss: -1332.1783 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -24619.4590 - accuracy: 0.5910 - val_loss: -78776.5547 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -376595.1562 - accuracy: 0.5910 - val_loss: -829120.5000 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -2579664.0000 - accuracy: 0.5910 - val_loss: -4750372.5000 - val_accuracy: 0.6108\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: -16141953.0000 - accuracy: 0.6000 - val_loss: -24886472.0000 - val_accuracy: 0.6121\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 3s 31ms/step - loss: -62960444.0000 - accuracy: 0.6065 - val_loss: -71408608.0000 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -193988624.0000 - accuracy: 0.5974 - val_loss: -202475808.0000 - val_accuracy: 0.5876\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: -428114816.0000 - accuracy: 0.6016 - val_loss: -413770112.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -888107200.0000 - accuracy: 0.5887 - val_loss: -788213440.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: -1734225280.0000 - accuracy: 0.5977 - val_loss: -1505732992.0000 - val_accuracy: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2de84c590>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model6 = Sequential([\n",
    "    #reducing vocab by reducing input_dim parameter\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=400, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.2),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model6.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model6.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6260a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 7ms/step - loss: -1827852288.0000 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1827852288.0, 0.5938144326210022]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(X_test_pad, y_test_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24af29d9",
   "metadata": {},
   "source": [
    "# Increase dropout rate from 0.2 to 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "145429c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: -345.7334 - accuracy: 0.5900 - val_loss: -2104.9451 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -38489.2148 - accuracy: 0.5910 - val_loss: -115524.0859 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -553081.6250 - accuracy: 0.5910 - val_loss: -1221967.5000 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -3753766.7500 - accuracy: 0.5910 - val_loss: -6587520.0000 - val_accuracy: 0.6070\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -14844507.0000 - accuracy: 0.5910 - val_loss: -22329606.0000 - val_accuracy: 0.6070\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 2s 26ms/step - loss: -43894780.0000 - accuracy: 0.5910 - val_loss: -60122128.0000 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -119916328.0000 - accuracy: 0.5890 - val_loss: -147600832.0000 - val_accuracy: 0.5168\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -341622848.0000 - accuracy: 0.5819 - val_loss: -278695552.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -735384512.0000 - accuracy: 0.5939 - val_loss: -704463040.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 2s 25ms/step - loss: -1525449600.0000 - accuracy: 0.5906 - val_loss: -1230534656.0000 - val_accuracy: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cc54dd10>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model7 = Sequential([\n",
    "    #reducing vocab by reducing input_dim parameter\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.3),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.3),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.3),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model7.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model7.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "15fa0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: -1389985920.0000 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1389985920.0, 0.5938144326210022]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(X_test_pad, y_test_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caebd17",
   "metadata": {},
   "source": [
    "# Reduce batch size from 32 to 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28784576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "194/194 [==============================] - 4s 20ms/step - loss: -13200.8711 - accuracy: 0.5910 - val_loss: -87963.7422 - val_accuracy: 0.6070\n",
      "Epoch 2/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -1302286.1250 - accuracy: 0.5910 - val_loss: -3719548.0000 - val_accuracy: 0.6070\n",
      "Epoch 3/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -16191035.0000 - accuracy: 0.5910 - val_loss: -31546556.0000 - val_accuracy: 0.6070\n",
      "Epoch 4/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -152907680.0000 - accuracy: 0.5887 - val_loss: -274532928.0000 - val_accuracy: 0.5528\n",
      "Epoch 5/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -979486400.0000 - accuracy: 0.5810 - val_loss: -1386160128.0000 - val_accuracy: 0.6070\n",
      "Epoch 6/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -3542244608.0000 - accuracy: 0.6090 - val_loss: -4240643584.0000 - val_accuracy: 0.6070\n",
      "Epoch 7/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -9729232896.0000 - accuracy: 0.5942 - val_loss: -10000198656.0000 - val_accuracy: 0.6070\n",
      "Epoch 8/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -21943973888.0000 - accuracy: 0.5932 - val_loss: -22015438848.0000 - val_accuracy: 0.6070\n",
      "Epoch 9/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -40994410496.0000 - accuracy: 0.5929 - val_loss: -37685833728.0000 - val_accuracy: 0.6070\n",
      "Epoch 10/10\n",
      "194/194 [==============================] - 4s 19ms/step - loss: -70941097984.0000 - accuracy: 0.5916 - val_loss: -65216573440.0000 - val_accuracy: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x323b31390>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout #import dropout layer\n",
    "#RNN model\n",
    "model8 = Sequential([\n",
    "    #reducing vocab by reducing input_dim parameter\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=300, input_length=50),\n",
    "    #input_dim = specifies the size of the vocabulary, i.e., the total number of unique words in the input text data.\n",
    "    #output_dim = 100, each word will be embedded into a dense vector of size 100.\n",
    "    #input_length = input sequences should have a length of 50 tokens after padding.\n",
    "    #tokenizer.word_index is a dictionary that maps words (tokens) to their corresponding integer indices.\n",
    "    LSTM(units=64),# LSTM layer processes sequential data by selectively retaining and updating information over time\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.3),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.3),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.3),#20% of the neurons in the dropout layer will be randomly set to zero\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model8.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model8.fit(X_train_pad, y_train_RNN, epochs=10, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8bb05c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: -68898283520.0000 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-68898283520.0, 0.5938144326210022]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.evaluate(X_test_pad, y_test_RNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
